### Google Cloud Vision API

[Cloud Vision 문서  |  Cloud Vision API  |  Google Cloud](https://cloud.google.com/vision/docs?hl=ko)

**1. 환경 설정 및 라이브러리 임포트**

- 필요한 라이브러리 및 환경 변수를 설정
- Google Cloud Vision API에 액세스하기 위한 인증 키 파일 경로를 환경 변수로 설정

```python
import os
from google.cloud import vision
```

**2. 이미지 혐오 점수 감지 함수 (`detect_image_obscenity`)**

- **`detect_image_obscenity`** : 이미지의 혐오 점수를 감지하고 유해 여부를 판단하는 주요 함수
- **`google.cloud.vision`** 라이브러리를 사용하여 이미지를 분석

```python
def detect_image_obscenity(image_path):
    """Google Cloud Vision API를 사용하여 이미지의 혐오 점수를 감지하고 유해 여부를 출력합니다."""
    client = vision.ImageAnnotatorClient()
```

**3. 이미지 파일 열기 및 읽기**

- 주어진 이미지 파일 경로에서 이미지 파일을 열고 읽음

```python
with open(image_path, "rb") as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
```

**4. 이미지 분석 및 혐오 점수 계산**

- **`safe_search_detection`** 메서드를 사용하여 이미지를 분석하고, 그 결과를 **`safe_search`** 변수에 저장
- 다양한 혐오 점수 (성인, 약물, 사기, 폭력, 선정)를 추출

```python
response = client.safe_search_detection(image=image)
 safe_search = response.safe_search_annotation

# 혐오 점수
    adult_likelihood = safe_search.adult
    medical_likelihood = safe_search.medical
    spoof_likelihood = safe_search.spoof
    violence_likelihood = safe_search.violence
    racy_likelihood = safe_search.racy
```

**5. 유해 여부 판단**

- **`LIKELY`** 또는 **`VERY_LIKELY`** 수준의 혐오 점수가 하나라도 있는 경우 해당 이미지를 유해하다고 판단

```python
# 혐오 점수가 "LIKELY" 또는 "VERY_LIKELY"인 경우 이미지를 유해하다고 판단
    harmful = (adult_likelihood >= 4 or medical_likelihood >= 4 or spoof_likelihood >= 4 or
               violence_likelihood >= 3 or racy_likelihood >= 3)
```

**6. 결과 반환**

- 이미지의 각 혐오 점수와 유해 여부를 포함하는 결과를 딕셔너리로 반환

```python
# 결과 반환
    return {
        "adult": adult_likelihood,
        "medical": medical_likelihood,
        "spoof": spoof_likelihood,
        "violence": violence_likelihood,
        "racy": racy_likelihood,
        "harmful": harmful,
    }
```

**7. 이미지 혐오 점수 및 유해 여부 확인**

- 예제 이미지 경로를 사용하여 **`detect_image_obscenity`** 함수를 호출하고, 결과 리턴

```python
# 이미지 혐오 점수 및 유해 여부 감지 함수 호출 예제
image_path = r"C:\Users\gram\Downloads\42933324-폭력적인-아버지는-가족의-대-히트.jpg"
result = detect_image_obscenity(image_path)
```

- 결과를 출력하여 이미지의 혐오 점수 및 유해 여부를 확인

```python
# 결과 출력
print("Image Obscenity Scores:")
print(f"Adult: {result['adult']}") #성인
print(f"Medical: {result['medical']}") #약물
print(f"Spoof: {result['spoof']}") #사기
print(f"Violence: {result['violence']}") #폭력
print(f"Racy: {result['racy']}") #선정

print("Image Harmful: ", result['harmful'])
```
